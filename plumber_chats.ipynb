{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/python/3.10.8/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.8/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/python/3.10.8/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue= \"Shower won't turn off water leaking\"\n",
    "cx_prompt= \"Act as a customer whose facing a plumbing problem. Answer the questions asked by the plumber.\\n\\nThe issue you are facing is:\"+ issue\n",
    "plumber_prompt= \"You are a plumber in the UK. You need to ask short questions to the customer and give a price quote.\\nPlease proceed step by step. Ask only one question at a time, and then ask the next one.\"\n",
    "p=[issue]\n",
    "messages= [{\"role\":\"system\", \"content\": plumber_prompt}]\n",
    "messages.append({\"role\":\"user\",\"content\": issue})\n",
    "chat = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\", messages=messages\n",
    "        )\n",
    "reply = chat.choices[0].message.content\n",
    "messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "transcript=[chat]\n",
    "tokens= [chat.usage.total_tokens]\n",
    "#print(messages)\n",
    "p.append(reply)\n",
    "h=[reply]\n",
    "cx_messages= [{\"role\":\"system\", \"content\": cx_prompt}]\n",
    "i=0\n",
    "while i<=15:\n",
    "    if \"Â£\" not in h[i] and i<20:\n",
    "        cx_messages.append({\"role\":\"user\", \"content\": h[i]})\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\", messages= cx_messages\n",
    "        )\n",
    "        res = response.choices[0].message.content\n",
    "        cx_messages.append({\"role\": \"assistant\", \"content\": res})\n",
    "        p.append(res)\n",
    "        transcript.append(response)\n",
    "        tokens.append(response.usage.total_tokens)\n",
    "        \n",
    "        messages.append({\"role\":\"user\",\"content\": res})\n",
    "        result = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\", messages= messages\n",
    "        )\n",
    "        replies = result.choices[0].message.content\n",
    "        messages.append({\"role\":\"assistant\",\"content\": replies})\n",
    "        \n",
    "        transcript.append(result)\n",
    "        tokens.append(result.usage.total_tokens)\n",
    "        h.append(replies)\n",
    "        p.append(replies)\n",
    "        #print(cx_messages)\n",
    "        #print(\"*\"*100)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>output</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shower won't turn off water leaking</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is the leak coming from the showerhead itself ...</td>\n",
       "      <td>{'id': 'chatcmpl-7T7FxvwPXYrE14cePwq6sAICphehd...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I believe the water is leaking from a differen...</td>\n",
       "      <td>{'id': 'chatcmpl-7T7FziskfV8bFmj7A5G9sCnlalxsR...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is the water leaking from the shower faucet or...</td>\n",
       "      <td>{'id': 'chatcmpl-7T7G1U0FrO1fUqXRYgBpUMDoAJWSk...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think the water is leaking from the shower f...</td>\n",
       "      <td>{'id': 'chatcmpl-7T7G3zpTPgR66jOgoPACtxMqXTKU3...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0                Shower won't turn off water leaking   \n",
       "1  Is the leak coming from the showerhead itself ...   \n",
       "2  I believe the water is leaking from a differen...   \n",
       "3  Is the water leaking from the shower faucet or...   \n",
       "4  I think the water is leaking from the shower f...   \n",
       "\n",
       "                                              output  total_tokens  \n",
       "0                                                  0             0  \n",
       "1  {'id': 'chatcmpl-7T7FxvwPXYrE14cePwq6sAICphehd...            81  \n",
       "2  {'id': 'chatcmpl-7T7FziskfV8bFmj7A5G9sCnlalxsR...            81  \n",
       "3  {'id': 'chatcmpl-7T7G1U0FrO1fUqXRYgBpUMDoAJWSk...           120  \n",
       "4  {'id': 'chatcmpl-7T7G3zpTPgR66jOgoPACtxMqXTKU3...           117  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.DataFrame(p,columns=[\"messages\"])\n",
    "transcripts= [0]\n",
    "for i in transcript:\n",
    "    transcripts.append(i)\n",
    "tok=[0]\n",
    "for i in tokens:\n",
    "    tok.append(i)\n",
    "df[\"output\"] = transcripts\n",
    "df[\"total_tokens\"] = tok\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"outputz1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
